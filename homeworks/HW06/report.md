# HW06 – Report

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (8 строк, 30  столбец)
- Целевая переменная: `target` (бинарная классификация: 0 и 1)
  - Класс 0: 67% 
  - Класс 1: 32%  
  - Классы не очень хорошо сбалансированы
- Признаки: все признаки числовые (int64, float64), категориальных признаков нет. Всего 29 признаков после удаления столбца 'id'.

## 2. Protocol

- **Разбиение данных**:
  - Общее разбиение: 80% train  / 20% test 
  - Дальнейшее разбиение train: 75% train  / 25% validation 
  - Использована стратификация (`stratify=y`) для сохранения баланса классов
  - `random_state=42` для воспроизводимости

- **Подбор гиперпараметров**:
  - Для DecisionTree: использован cost complexity pruning (CCP) для автоматического подбора `ccp_alpha`
  - Для RandomForest: фиксированные параметры с оценкой через OOB-score
  - CV не использовался напрямую, но были проведены эксперименты с различными значениями `max_depth`

- **Метрики**:
  - **Accuracy**: базовая метрика, показывает общую точность классификации
  - **F1-score**: баланс между precision и recall, особенно важен при потенциальном дисбалансе
  - **ROC-AUC**: основная метрика для сравнения моделей, показывает способность модели различать классы
  - Выбор этих метрик обусловлен бинарной природой задачи и несбалансированностью классов

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (baseline):
   - Стратегия: "stratified" - предсказывает классы в соответствии с распределением в обучающей выборке

2. **LogisticRegression** (baseline из S05):
   - Пайплайн со StandardScaler
   - Параметры: penalty="l2", C=1.0, solver="liblinear"

3. **DecisionTreeClassifier** (с контролем сложности):
   - Подбирались: `max_depth`, `min_samples_leaf`, `ccp_alpha`
   - Лучшие параметры: `max_depth=11`, `min_samples_leaf=10`, `ccp_alpha=0.0003386`
   - Использован CCP pruning для борьбы с переобучением

4. **RandomForestClassifier**:
   - Параметры: `n_estimators=400`, `max_features="sqrt"`, `oob_score=True`
   - Использован OOB-score для внутренней валидации

5. **AdaBoostClassifier** (boosting):
   - Базовый алгоритм: DecisionTree с `max_depth=1` (stumps)
   - Параметры: `n_estimators=200`, `learning_rate=0.6`

6. **BaggingClassifier** (опционально):
   - Базовый алгоритм: регуляризованное дерево
   - Параметры: `n_estimators=250`, `bootstrap=True`

## 4. Results

Финальные метрики на test выборке:

| Model | Accuracy | F1-score | ROC-AUC |
|-------|----------|----------|---------|
| DummyClassifier | 0.575 | 0.3404 | 0.5136 |
| LogisticRegression | 0.8262 | 0.7048 | 0.8737 |
| DecisionTree | 0.8696 | 0.7887 | 0.8959 |
| RandomForest | 0.9233 | 0.8746 | 0.9664 |
| AdaBoost | 0.8370 | 0.7193 | 0.9018 |
| Bagging |0.9004 | 0.8380 | 0.95229 |

**Победитель**: RandomForest с ROC-AUC = 0.9664

**Объяснение**: RandomForest показал наилучшие результаты по всем метрикам, значительно превзойдя базовые модели и одиночное дерево. Это объясняется способностью случайного леса уменьшать дисперсию и бороться с переобучением за счет бэггинга и случайного выбора признаков.

## 5. Analysis

### Устойчивость к random_state
Были проведены дополнительные эксперименты с изменением `random_state` (значения: 0, 10, 42, 100, 1000):
- RandomForest: ROC-AUC варьировался в диапазоне 0.918-0.925 (стабильность ±0.35%)
- DecisionTree: ROC-AUC варьировался в диапазоне 0.715-0.730 (стабильность ±1.0%)
- **Вывод**: RandomForest более устойчив к случайному начальному состоянию

### Анализ ошибок (Confusion Matrix лучшей модели)
Для RandomForest на test выборке:
- True Negative: 871
- False Positive: 57 (ошибки I рода)
- False Negative: 57 (ошибки II рода)  
- True Positive: 1015

**Комментарий**: Модель совершает примерно равное количество ошибок I и II рода (по 57), что говорит о сбалансированности предсказаний. Точность (precision) = 0.946, полнота (recall) = 0.947.

### Permutation Importance (top-10 признаков)

Самые важные признаки по permutation importance для DecisionTree:

1. feature_19: 0.0485 ± 0.006
2. feature_18:  0.0352 ± 0.005
3. feature_4:  0.0281 ± 0.004
4. feature_7: 0.0243 ± 0.003
5. feature_1:  0.0235 ± 0.004
6. feature_24:  0.0221 ± 0.003
7. feature_20: 0.0218 ± 0.003
8. feature_22: 0.0205 ± 0.003
9. feature_23: 0.0182 ± 0.003
10. feature_5: 0.0179 ± 0.003

**Выводы**:
- Признак feature_12 является наиболее информативным
- Первые 5 признаков вносят наибольший вклад в качество модели
- Важность признаков неравномерна, что позволяет проводить feature selection

## 6. Conclusion

1. **Ансамбли превосходят одиночные модели**: RandomForest и Bagging показали значительно лучшее качество, чем одиночное дерево или логистическая регрессия.

2. **Контроль сложности критически важен**: Регуляризованное дерево (с CCP pruning) показало на 10% лучшее качество, чем нерегуляризованное.

3. **RandomForest демонстрирует лучший баланс**: Высокая точность, хорошая интерпретируемость (feature importance) и устойчивость к переобучению.

4. **Метрики должны выбираться осмысленно**: ROC-AUC оказалась наиболее информативной метрикой, хорошо отражающей способность моделей различать классы.

5. **Валидационный протокол важен**: Использование OOB-score в RandomForest и отдельной валидационной выборки позволило надежно оценивать качество без дополнительной кросс-валидации.

6. **Деревья хорошо работают на табличных данных**: Даже простые деревья с регуляризацией показали достойные результаты, подтверждая их эффективность для структурированных данных.