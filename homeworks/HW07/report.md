# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 , 9)
- Признаки: f01-f08 (8 числовых признаков)
- Пропуски: нет
- "Подлости" датасета: высокая размерность
### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: ( 8000, 4)
- Признаки: x1, x2, z_noise (3 числовых признака)
- Пропуски: нет
- "Подлости" датасета: 2D данные с шумовым признаком

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: x1, x2, f_corr, f_noise (4 числовых признака)
- Пропуски: нет
- "Подлости" датасета: 2D данные с коррелированным и шумовым признаками

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: Для всех датасетов применен единый пайплайн препроцессинга:
- Масштабирование:StandardScaler()
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz 
- Визуализация: PCA(2D) 

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans: 2-15 для dataset01, 2-10 для dataset02 и dataset03
- Один из:
  - DBSCAN :метод 4-го соседа (k-distance plot) eps = [0.5×оптимальный, оптимальный, 1.5×оптимальный]; min_samples = [5, 10, 15]

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans Оптимальное K: 2
- Метрики (silhouette / DB / CH): Silhouette Score: 0.5216, Calinski-Harabasz: 11786.95, Davies-Bouldin: 0.6853
- Если был DBSCAN(eps=1.778, min_samples=5): Кластеров: 2, Шум: 0.0%
- Коротко: Оба алгоритма показывают одинаковое качество, KMeans выбран за простоту интерпретации. Данные содержат два хорошо разделенных сферических кластера.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.686, min_samples=10
- Метрики (silhouette / DB / CH): silhouette: 0.3321, CH (Calinski-Harabasz): 144.61, DB (Davies-Bouldin): 0.6271
- Если был DBSCAN: Доля шума: 4.0% (318 точек из 8000)
- Коротко:KMeans с k=2 показал silhouette=0.3069, DBSCAN обнаружил 5 кластеров с лучшим качеством.DBSCAN лучше подходит для данных с шумом и кластерами произвольной формы. Наличие 5 кластеров и 4% шума соответствует структуре данных.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans с k=3 (n_init=10, random_state=42)
- Метрики (silhouette / DB / CH): silhouette:  0.3155, CH (Calinski-Harabasz): 6957.16, DB (Davies-Bouldin): 1.1577
- Если был DBSCAN: DBSCAN не смог найти валидные кластеры при тестируемых параметрах
- Коротко:KMeans - единственный рабочий алгоритм для этих данных

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
KMeans показал худшие результаты на Dataset B (silhouette=0.3069 vs 0.3321 у DBSCAN). Причина: KMeans предполагает сферические кластеры одинакового размера, а данные содержат кластеры произвольной формы и шум (признак z_noise).
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
BSCAN выиграл на Dataset B, обнаружив 5 кластеров вместо 2 и показав лучший silhouette. Причина: DBSCAN способен находить кластеры произвольной формы и автоматически обрабатывать выбросы как шум.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
1. Масштабирование: критически важно для корректной работы обоих алгоритмов
2. Шумовые признаки: на Dataset B наличие z_noise ухудшило результаты KMeans

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
Проверка устойчивости KMeans для Dataset A: 5 запусков с random_state = [0, 10, 20, 30, 40], сравнение через Adjusted Rand Index (ARI).
- Что получилось (в 3-6 строк)
- Средний ARI: 1.0000
  - Стандартное отклонение: 0.0000
  - Минимальный ARI: 1.0000
  - Максимальный ARI: 1.0000
  - Все 5 запусков дали идентичные разбиения
- Вывод: устойчиво. KMeans демонстрирует абсолютную устойчивость для Dataset A. Это объясняется хорошо разделенными сферическими кластерами, где инициализация не влияет на конечный результат.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) 
- 3-6 строк выводов
1. Dataset A: два четких кластера
2. Dataset B: DBSCAN выделил 5 компактных групп, 4% точек определены как шум, что соответствует наличию z_noise
3. Dataset C: кластеры слабо разделены, различия в основном по коррелированным признакам (f_corr)
4.  Качество интерпретации напрямую зависит от качества кластеризации
## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.
1.  KMeans эффективен для сферических кластеров, DBSCAN - для данных с шумом и кластерами произвольной формы. Выбор алгоритма должен зависеть от структуры данных.
2.  Нельзя полагаться на одну метрику.
3. Препроцессинг обязателен
4. Визуализация очень очень помогает
5. Проверка устойчивости необходима